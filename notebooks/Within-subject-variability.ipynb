{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "domestic-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test within subject variability \n",
    "\n",
    "# s1 ... s50 listen to the same story \n",
    "# Does f(s1) generalize better to f(s1) or f(s2). delta is the distance  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "waiting-spread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/private/home/ccaucheteux/hasson-syntaxe-vs-semantics\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "general-knitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlate(X, Y):\n",
    "    if X.ndim == 1:\n",
    "        X = X[:, None]\n",
    "    if Y.ndim == 1:\n",
    "        Y = Y[:, None]\n",
    "    X = X - X.mean(0)\n",
    "    Y = Y - Y.mean(0)\n",
    "    SX2 = (X ** 2).sum(0) ** 0.5\n",
    "    SY2 = (Y ** 2).sum(0) ** 0.5\n",
    "    SXY = (X * Y).sum(0)\n",
    "    return SXY / (SX2 * SY2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "communist-minneapolis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KFold(5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "filled-watch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "def encode(X, Y1, Y2, \n",
    "           model=RidgeCV(np.logspace(-2, 8, 10)), \n",
    "           cv = KFold(5, shuffle=False)):\n",
    "    assert Y1.shape == Y2.shape\n",
    "    \n",
    "    r = np.zeros((cv.get_n_splits(), 2, 2, *Y1.shape[1:]))\n",
    "    for i, (train, test) in enumerate(cv.split(X)):\n",
    "        for j, Y in enumerate([Y1, Y2]):\n",
    "            model.fit(X[train], Y[train])\n",
    "            pred = model.predict(X[test])\n",
    "            #import pdb\n",
    "            #pdb.set_trace()\n",
    "            r[i, j, 0] = correlate(Y1[test], pred)\n",
    "            r[i, j, 1] = correlate(Y2[test], pred)\n",
    "    return r        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "skilled-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from encoding.fmri import convolve_features\n",
    "from nilearn import signal\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "from src import paths\n",
    "from src.encode import encode_with_folds\n",
    "from src.get_bold import get_bold\n",
    "from src.get_features import load_precomputed_features\n",
    "from src.preprocess_stim import add_pulses_to_stim, get_stimulus\n",
    "from src.task_dataset import get_task_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bizarre-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src import paths\n",
    "from src.get_bold import get_bold\n",
    "from src.task_dataset import get_task_df\n",
    "from pathlib import Path\n",
    "\n",
    "def get_brain(hemi, df_task, task, save_path, space = \"fsaverage6\", \n",
    "             scaler = RobustScaler(quantile_range=(0.1, 99.9))):\n",
    "    print(task, hemi)\n",
    "    bold = []\n",
    "    errors = []\n",
    "    subs = []\n",
    "    df_task = df_task.query(\"audio_task==@task\")\n",
    "    print(len(df_task))\n",
    "    for i, row in tqdm(df_task.iterrows()):\n",
    "        if i%100==0:\n",
    "            print(\"i\", i)\n",
    "        # Load bold responses\n",
    "        gii_fname = f\"{row.subject}_task-{row.bold_task}_*space-{space}_hemi-{hemi}_desc-clean.func.gii\"\n",
    "        try:\n",
    "            subj_data = get_bold(\n",
    "            gii_fname, row.subject, exclude=True, afni_dir=paths.afni_dir_nosmooth\n",
    "        )\n",
    "        except AssertionError as e:\n",
    "            print(\"Assertion error\")\n",
    "            errors.append(gii_fname)\n",
    "            continue\n",
    "        if subj_data is None:\n",
    "            errors.append(gii_fname)\n",
    "            continue        \n",
    "        subj_data = scaler.fit_transform(subj_data[row.onset:])\n",
    "        bold.append(subj_data)\n",
    "        subs.append(row.subject)\n",
    "    if len(bold)==0:\n",
    "        med_bolds = {\"bold\": None, \"count\":0, \"errors\":errors}\n",
    "    else:\n",
    "        nr, nc = np.stack([b.shape for b in bold]).min(0)\n",
    "        print(f\"Cutting to {nr}, {nc}\")\n",
    "        count = len(bold)\n",
    "        bold = [b[:nr, :nc] for b in bold]\n",
    "        #bold = np.median(np.stack(bold), axis=0)\n",
    "        med_bolds = {\"bold\": np.stack(bold), \"count\":count, \"task\":task, \"errors\":errors, \"subjects\":subs} \n",
    "    return med_bolds\n",
    "    \n",
    "    #Path(save_path).parent.mkdir(exist_ok=True, parents=True)\n",
    "    #np.save(save_path, med_bolds)\n",
    "    \n",
    "def get_feats(feature_files, audio_task, word_idx, convolve_model=\"fir\", n_delays=4, \n",
    "             scaler = StandardScaler()):\n",
    "    word_idx = word_events.word_index.values\n",
    "\n",
    "    # Extract features from stimulus\n",
    "    feature_task_files = [Path(str(f) % str(audio_task)) for f in feature_files]\n",
    "    assert np.all(\n",
    "        [f.is_file() for f in feature_task_files]\n",
    "    ), f\"!!!!!! NOT EXIXTS : {feature_task_files}\"\n",
    "    features = load_precomputed_features(\n",
    "        audio_task, feature_task_files, idx=word_idx\n",
    "    )\n",
    "\n",
    "    assert np.all([len(feat) == len(word_idx) for feat in features])\n",
    "    \n",
    "    convolved = []\n",
    "    for feat in features:\n",
    "        feat = scaler.fit_transform(feat)\n",
    "        feat = convolve_features(\n",
    "        events, feat, model=convolve_model, n_delays=n_delays\n",
    "    )\n",
    "        feat = scaler.fit_transform(feat)\n",
    "        convolved.append(feat)\n",
    "    \n",
    "    return convolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "brazilian-victoria",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task = get_task_df()\n",
    "#get_brain(hemi, df_task, task, save_path, space = \"fsaverage6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "objective-circus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapessocial L\n",
      "59\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ba2b20bc964bd09f5087fb8e423f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding sub-238_task-shapessocial_space-fsaverage6_hemi-L_desc-clean.func.gii!\n",
      "Cutting to 306, 40962\n"
     ]
    }
   ],
   "source": [
    "test = get_brain(\"L\", df_task, \"shapessocial\", None, space = \"fsaverage6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "optional-carolina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 306, 40962)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"bold\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "interracial-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_task = \"shapessocial\"\n",
    "trim_init = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "rotary-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "TR = 1.5\n",
    "subj_data = test[\"bold\"].copy()\n",
    "n_pulse = subj_data.shape[1]\n",
    "\n",
    "\n",
    "stimuli = get_stimulus(audio_task)\n",
    "events = add_pulses_to_stim(stimuli, n_pulse, TR=TR)\n",
    "onset = np.floor(stimuli.dropna(subset=[\"onset\"]).iloc[0].onset / TR)\n",
    "onset = int(np.max([trim_init, onset]))\n",
    "offset = np.ceil(stimuli.dropna(subset=[\"offset\"]).iloc[-1].offset / TR)\n",
    "offset = int(offset)\n",
    "\n",
    "# Filter subj data\n",
    "subj_data = subj_data[:, onset:offset]\n",
    "\n",
    "events = events.query(\"volume<@offset and volume>=@onset\")\n",
    "events[\"volume\"] -= onset\n",
    "word_events = events.query(\"condition == 'word'\")\n",
    "\n",
    "\n",
    "word_idx = word_events.word_index.values\n",
    "features = get_feats(feature_files, audio_task, word_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "productive-journalist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58, 273, 40962)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "therapeutic-investor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/private/home/ccaucheteux/hasson-syntaxe-vs-semantics/data/embeddings/0206_wordembed/%s/3_phone_features.pth')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(scores.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "assured-triangle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01298332, -0.01403668, -0.03671308, ..., -0.11719131,\n",
       "       -0.11090633, -0.09700501])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k0 = Path('/private/home/ccaucheteux/hasson-syntaxe-vs-semantics/data/embeddings/0206_wordembed/%s/3_phone_features.pth')\n",
    "scores[k0][0, 1, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "interstate-patrol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subj_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "separated-trouble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3+3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "alpine-folks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([PosixPath('/private/home/ccaucheteux/hasson-syntaxe-vs-semantics/data/embeddings/0206_wordembed/%s/3_phone_features.pth'), PosixPath('/private/home/ccaucheteux/hasson-syntaxe-vs-semantics/data/embeddings/0206_wordembed/%s/sum-gpt2-0.pth')])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "french-seafood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2, 2, 40962)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[Path('/private/home/ccaucheteux/hasson-syntaxe-vs-semantics/data/embeddings/0206_wordembed/%s/sum-gpt2-0.pth')].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "cv = KFold(5, shuffle=False)\n",
    "for lab, feat in zip(feature_files, features):\n",
    "    scores[lab] = np.zeros((len(subj_data), len(subj_data), 5, 2, 2, 40962))\n",
    "    for i in range(len(subj_data)):\n",
    "        for j in np.arange(i+1, len(subj_data)):\n",
    "            print(i, j)\n",
    "            scores[lab][i, j] = encode(feat, subj_data[i], subj_data[j], \n",
    "                   model=RidgeCV(np.logspace(1, 8, 8)), \n",
    "                   cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "monthly-agency",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_FOLDER = \"0206_wordembed\"\n",
    "feature_files = [paths.embeddings / FEATURE_FOLDER / \"%s\" / f\"{feat}.pth\" for feat in [\"3_phone_features\", \n",
    "                                                                                      \"sum-gpt2-0\",\n",
    "                                                                                      \"sum-gpt2-9\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-gilbert",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli = get_stimulus(audio_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-jumping",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "driven-rebel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_task</th>\n",
       "      <th>subject</th>\n",
       "      <th>comprehension</th>\n",
       "      <th>bold_task</th>\n",
       "      <th>onset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pieman</td>\n",
       "      <td>sub-001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pieman</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pieman</td>\n",
       "      <td>sub-002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pieman</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pieman</td>\n",
       "      <td>sub-003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pieman</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pieman</td>\n",
       "      <td>sub-004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pieman</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pieman</td>\n",
       "      <td>sub-005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pieman</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>black</td>\n",
       "      <td>sub-311</td>\n",
       "      <td>0.66</td>\n",
       "      <td>black</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>black</td>\n",
       "      <td>sub-312</td>\n",
       "      <td>0.84</td>\n",
       "      <td>black</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>black</td>\n",
       "      <td>sub-313</td>\n",
       "      <td>0.88</td>\n",
       "      <td>black</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>black</td>\n",
       "      <td>sub-314</td>\n",
       "      <td>0.92</td>\n",
       "      <td>black</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>black</td>\n",
       "      <td>sub-315</td>\n",
       "      <td>0.60</td>\n",
       "      <td>black</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>638 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    audio_task  subject  comprehension bold_task onset\n",
       "0       pieman  sub-001            NaN    pieman     0\n",
       "1       pieman  sub-002            NaN    pieman     0\n",
       "2       pieman  sub-003            NaN    pieman     0\n",
       "3       pieman  sub-004            NaN    pieman     0\n",
       "4       pieman  sub-005            NaN    pieman     0\n",
       "..         ...      ...            ...       ...   ...\n",
       "633      black  sub-311           0.66     black     8\n",
       "634      black  sub-312           0.84     black     8\n",
       "635      black  sub-313           0.88     black     8\n",
       "636      black  sub-314           0.92     black     8\n",
       "637      black  sub-315           0.60     black     8\n",
       "\n",
       "[638 rows x 5 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "unique-measure",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-102-51316cedfd55>:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_task.groupby(\"audio_task\")[\"subject\", \"duration\"].agg([\"nunique\", \"first\"])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Columns not found: 'duration'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-51316cedfd55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_task\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"audio_task\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"subject\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"duration\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nunique\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"first\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/hasson/lib/python3.8/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1533\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m             )\n\u001b[0;32m-> 1535\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/hasson/lib/python3.8/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    266\u001b[0m                     \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 )\n\u001b[0;32m--> 268\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Columns not found: {str(bad_keys)[1:-1]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Columns not found: 'duration'\""
     ]
    }
   ],
   "source": [
    "df_task.groupby(\"audio_task\")[\"subject\", \"duration\"].agg([\"nunique\", \"first\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-integer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task = get_task_df()\n",
    "    df_task = df_task.query(\"subject==@subject and audio_task==@audio_task\")\n",
    "    print(df_task)\n",
    "    row = df_task.iloc[0]\n",
    "    audio_onset = row.onset\n",
    "    audio_task = row.audio_task\n",
    "    bold_task = row.bold_task\n",
    "\n",
    "    r = {}\n",
    "    features = None\n",
    "    for hemi in hemis:\n",
    "        # Load bold responses\n",
    "        gii_fname = (\n",
    "            f\"{subject}_task-{bold_task}_*space-{space}_hemi-{hemi}_desc-clean.func.gii\"\n",
    "        )\n",
    "        if smooth:\n",
    "            afni_dir = paths.afni_dir\n",
    "        else:\n",
    "            afni_dir = paths.afni_dir_nosmooth\n",
    "        subj_data = get_bold(gii_fname, subject, exclude=True, afni_dir=afni_dir)\n",
    "        if subj_data is None:\n",
    "            return\n",
    "\n",
    "        # Trim bold w.r.t onset timing of the audio file => everything starts at 0 from now on\n",
    "        subj_data = subj_data[audio_onset:, :]\n",
    "\n",
    "        # Load stimulus\n",
    "        stimuli = get_stimulus(audio_task)\n",
    "\n",
    "        # Merge pulses and stimulus\n",
    "        n_pulse = len(subj_data)\n",
    "        events = add_pulses_to_stim(stimuli, n_pulse, TR=TR)\n",
    "\n",
    "        # Cut extra pulses\n",
    "        onset = np.floor(stimuli.dropna(subset=[\"onset\"]).iloc[0].onset / TR)\n",
    "        onset = int(np.max([trim_init, onset]))\n",
    "        offset = np.ceil(stimuli.dropna(subset=[\"offset\"]).iloc[-1].offset / TR)\n",
    "        offset = int(offset)\n",
    "\n",
    "        subj_data = subj_data[onset:offset]\n",
    "        events = events.query(\"volume<@offset and volume>=@onset\")\n",
    "        events[\"volume\"] -= onset\n",
    "        assert len(subj_data) == len(events.query(\"condition=='Pulse'\"))\n",
    "\n",
    "        word_events = events.query(\"condition == 'word'\")\n",
    "        word_idx = word_events.word_index.values\n",
    "\n",
    "        # Extract features from stimulus\n",
    "        feature_task_files = [Path(str(f) % str(audio_task)) for f in feature_files]\n",
    "        assert np.all(\n",
    "            [f.is_file() for f in feature_task_files]\n",
    "        ), f\"!!!!!! NOT EXIXTS : {feature_task_files}\"\n",
    "        features = load_precomputed_features(\n",
    "            audio_task, feature_task_files, idx=word_idx\n",
    "        )\n",
    "\n",
    "        assert np.all([len(feat) == len(word_events) for feat in features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-boston",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp_single_tasks(\n",
    "    subject,\n",
    "    audio_task,\n",
    "    feature_files=[],  # [\"wordpos\", \"seqlen\", \"gpt2.0\"],\n",
    "    hemis=[\"L\", \"R\"],\n",
    "    smooth=False,\n",
    "    space=\"fsaverage6\",\n",
    "    TR=1.5,\n",
    "    trim_init=2,\n",
    "    use_torch=False,\n",
    "    convolve_model=\"fir\",\n",
    "    high_pass=None,\n",
    "    n_folds=5,\n",
    "    zero_out=None,\n",
    "    regress_out=None,\n",
    "    fit_intercept=False,\n",
    "    other_task=False,\n",
    "    average_folds=True,\n",
    "    n_delays=4,\n",
    "    scaler=RobustScaler(quantile_range=(0.1, 99.9)),\n",
    "):\n",
    "\n",
    "    \n",
    "\n",
    "        # ENCODE HERE \n",
    "\n",
    "        r[hemi] = {}\n",
    "        for lab, feat in zip(feature_files, features):\n",
    "            feat = scaler.fit_transform(feat)\n",
    "            convolved = convolve_features(\n",
    "                events, feat, model=convolve_model, n_delays=n_delays\n",
    "            )\n",
    "            convolved = scaler.fit_transform(convolved)\n",
    "\n",
    "            # Encode\n",
    "            bold = subj_data.copy()\n",
    "            valid = bold.std(0) > 0\n",
    "            bold[:, valid] = scaler.fit_transform(bold[:, valid])\n",
    "\n",
    "            # CONFOUNDS\n",
    "            if zero_out is not None and zero_out[lab] is not None:\n",
    "                to_zero_out = list(zero_out[lab]) * n_delays\n",
    "                to_zero_out = np.array(to_zero_out)\n",
    "            else:\n",
    "                to_zero_out = None\n",
    "\n",
    "            if regress_out is not None and regress_out[lab] is not None:\n",
    "                to_regress_out = list(regress_out[lab]) * n_delays\n",
    "                to_regress_out = np.array(to_regress_out)\n",
    "            else:\n",
    "                to_regress_out = None\n",
    "\n",
    "            if average_folds:\n",
    "                r[hemi][lab] = np.zeros(bold.shape[1])\n",
    "            else:\n",
    "                r[hemi][lab] = np.zeros((bold.shape[1], n_folds))\n",
    "            r[hemi][lab][valid] = encode_with_folds(\n",
    "                convolved,\n",
    "                bold[:, valid],\n",
    "                n_folds=n_folds,\n",
    "                average_folds=average_folds,\n",
    "                estimator=RidgeCV(\n",
    "                    np.logspace(-1, 8, 10),\n",
    "                    fit_intercept=fit_intercept,\n",
    "                ),\n",
    "                to_regress_out=to_regress_out,\n",
    "                to_zero_out=to_zero_out,\n",
    "                groups=None,\n",
    "            )\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(X1, X2, Y1, Y2):\n",
    "    \n",
    "    r1 = np.zeros(*Y1.shape[1:])\n",
    "    r2 = np.zeros(*Y1.shape[1:])\n",
    "    for train, test in cv.split(X1):\n",
    "        for Xa, Ya, Xb, Yb in zip([X1, X2], \n",
    "                                  [Y1, Y2],\n",
    "                                  [X2, X1],\n",
    "                                  [Y2, Y1]):\n",
    "            model.fit(Xa[train], Ya[train])\n",
    "            preda = model.predict(Xa[test])\n",
    "            predb = model.predict(Xb[test])\n",
    "\n",
    "        model.fit(X2[train], )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(X, Y):\n",
    "    \"\"\"\n",
    "    X of shape n_samples, n_conditions, n_features\n",
    "    Y same\n",
    "    \"\"\"\n",
    "    \n",
    "    r = np.zeros(*X.shape[1:])\n",
    "    for train, test in cv.split(X):\n",
    "        for \n",
    "        model.fit(X[i, train], Y[i, train])\n",
    "        pred[i] = model.predict(X1[test])\n",
    "\n",
    "        model.fit(X2[train], )\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hasson",
   "language": "python",
   "name": "hasson"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
